{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "## Álvaro Andrés Esquivel Gómez 11002822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import dump, load\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import resample\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from scipy import stats\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alvar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-val-test split \n",
    "El primer paso es separar los datos en entrenamiento, validación y pruebas:\n",
    "\n",
    "* separar datos en entrenamiento y pruebas. Por ejemplo usando: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "* tomar una porción de datos de entrenamiento del paso anterior para validación. Puede ser aplicando nuevamente https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       "1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       "3      1      0            113803  53.1000  C123        S           Upper   \n",
       "4      0      0            373450   8.0500   NaN        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  \n",
       "0             M                  N  \n",
       "1             F                  Y  \n",
       "2             F                  Y  \n",
       "3             F                  Y  \n",
       "4             M                  N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando los datos\n",
    "data = pd.read_csv (r'data_titanic_proyecto.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch Embarked passenger_class passenger_sex  \\\n",
       "0  22.0      1      0        S           Lower             M   \n",
       "1  38.0      1      0        C           Upper             F   \n",
       "2  26.0      0      0        S           Lower             F   \n",
       "3  35.0      1      0        S           Upper             F   \n",
       "4  35.0      0      0        S           Lower             M   \n",
       "\n",
       "  passenger_survived  \n",
       "0                  N  \n",
       "1                  Y  \n",
       "2                  Y  \n",
       "3                  Y  \n",
       "4                  N  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quitando variables que no aportan informacion al modelo\n",
    "data = data.drop(['PassengerId', 'Fare', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "print(data.shape)\n",
    "data.head()\n",
    "#entrenamiento, validacion = train_test_split(data, test_size=0.80, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Age                 891 non-null    float64\n",
      " 1   SibSp               891 non-null    int64  \n",
      " 2   Parch               891 non-null    int64  \n",
      " 3   Embarked            889 non-null    object \n",
      " 4   passenger_class     891 non-null    object \n",
      " 5   passenger_sex       891 non-null    object \n",
      " 6   passenger_survived  891 non-null    object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 48.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remplaza valores NaN con 0\n",
    "data[\"Age\"] = data[\"Age\"].replace(np.nan, 0)\n",
    "print(data.info())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64 \n",
      " Lower     491\n",
      "Upper     216\n",
      "Middle    184\n",
      "Name: passenger_class, dtype: int64 \n",
      " M    577\n",
      "F    314\n",
      "Name: passenger_sex, dtype: int64 \n",
      " N    549\n",
      "Y    342\n",
      "Name: passenger_survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Copia variables categoricas\n",
    "#data = data.select_dtypes(include=['object']).copy()\n",
    "#cat_data.head()\n",
    "#Variables cono datos null\n",
    "#print(cat_data.isnull().sum())\n",
    "#Elimina los valores vacios\n",
    "data = data.fillna(data['Embarked'].value_counts().index[0])\n",
    "#print(cat_data.isnull().sum())\n",
    "print(data['Embarked'].value_counts(),\"\\n\", data['passenger_class'].value_counts(),\"\\n\", \n",
    "      data['passenger_sex'].value_counts(),\"\\n\", data['passenger_survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch  Embarked  passenger_class  passenger_sex  \\\n",
       "0  22.0      1      0         1                1              1   \n",
       "1  38.0      1      0         2                3              0   \n",
       "2  26.0      0      0         1                1              0   \n",
       "3  35.0      1      0         1                3              0   \n",
       "4  35.0      0      0         1                1              1   \n",
       "5   0.0      0      0         3                1              1   \n",
       "6  54.0      0      0         1                3              1   \n",
       "7   2.0      3      1         1                1              1   \n",
       "8  27.0      0      2         1                1              0   \n",
       "9  14.0      1      0         2                2              0   \n",
       "\n",
       "   passenger_survived  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   0  \n",
       "7                   0  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remplazando valores categoricos\n",
    "replace_map = {'Embarked': {'S': 1, 'C': 2, 'Q': 3}, 'passenger_class': {'Lower': 1, 'Middle': 2, 'Upper': 3}, \n",
    "               'passenger_sex': {'F': 0, 'M': 1}, 'passenger_survived': {'N': 0, 'Y': 1}}\n",
    "data.replace(replace_map, inplace=True)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (569, 7) test: (179, 7) validation: (143, 7)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.20, random_state = 10)\n",
    "train, validation = train_test_split(train, test_size=0.20, random_state = 10)\n",
    "print(\"Train:\", train.shape, \"test:\", test.shape, \"validation:\", validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble learning:\n",
    "Se aplicará ensemble learning para crear una \"votación mayoritaria\" con distintos tipos de modelos, con el objetivo de simplificar el problema 2 de estos modelos se harán usando scikit-learn y su función   .fit(x,y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample: [0.1, 0.6, 0.1, 0.4, 0.3, 0.4]\n"
     ]
    }
   ],
   "source": [
    "data2 = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# prepare bootstrap sample\n",
    "boot = resample(data2, replace=True, n_samples=6, random_state=2)\n",
    "print('Bootstrap Sample: %s' % boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de evalueación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [accuracy, porcentaje_error, precision_score, recall_score, f1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = ['accuracy','porcentaje_error', 'precision_score', 'recall_score', 'f1_score']\n",
    "evaluation_matrix  = pd.DataFrame(columns=columnas)\n",
    "\n",
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion calculo de evaluaciones y agrega a matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agegar_resultados(y_test, y_hat, index_name):\n",
    "\n",
    "    error_squared = mean_squared_error(y_test, y_hat)\n",
    "    print(\"error_squared:\", error_squared)\n",
    "    acc_reg_log = accuracy_score(y_test, y_hat)\n",
    "    print(\"accuracy o exactitud\", acc_reg_log)\n",
    "    porcentaje_error = 1 - acc_reg_log\n",
    "    print(\"porcentaje de error\", porcentaje_error)\n",
    "    p_score = precision_score(y_test, y_hat, average='binary')\n",
    "    print(\"precision_score\", p_score)\n",
    "    r_score = recall_score(y_test, y_hat, average='binary')\n",
    "    print(\"recall_score\", r_score)\n",
    "    f_score = f1_score(y_test, y_hat, average='binary')\n",
    "    print(\"f1 score\", f_score)\n",
    "\n",
    "    #Agrego al dataframe \n",
    "    evaluation_data = pd.DataFrame({\"accuracy\":acc_reg_log, \"porcentaje_error\":porcentaje_error, \n",
    "                                    \"precision_score\":p_score, \"recall_score\":r_score, \"f1_score\":f_score}, \n",
    "                                   index=[index_name]) \n",
    "    return evaluation_matrix.append(evaluation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(train, test, y):\n",
    "    \n",
    "    X_train = train.iloc[:, train.columns != y]\n",
    "    Y_train = train.iloc[:, train.columns == y]\n",
    "    #print(\"X_train\\n\",X_train, \"\\n\\nY_train\\n\", Y_train)\n",
    "    x_test = test.iloc[:, test.columns != y]\n",
    "    y_test = test.iloc[:, test.columns == y]\n",
    "    #print(\"x_test\\n\",X_train, \"\\n\\y_test\\n\", Y_train)\n",
    "    \n",
    "    #Creacion del modelo de arboles\n",
    "    classifi = DecisionTreeClassifier(random_state = 0)  \n",
    "    #Entrenamiento\n",
    "    classifi.fit(X_train, Y_train) \n",
    "    \n",
    "    #Prediccion \n",
    "    y_pred = classifi.predict(x_test).astype(int)\n",
    "    \n",
    "    #Fecha y hora del modelo para almacenar\n",
    "    now = datetime.now()\n",
    "    fecha_hora = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    #String de configuración para cada experimento\n",
    "    str_experimento = \"decision_tree_\"+fecha_hora\n",
    "    \n",
    "    #Almacena el modelo \n",
    "    dump(classifi, str_experimento+\".joblib\") \n",
    "    \n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    return y_pred, error\n",
    "\n",
    "#X_train = train.iloc[:, 0:8]\n",
    "#Y_train = train.iloc[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       0, 0, 0]), 0.20670391061452514)\n"
     ]
    }
   ],
   "source": [
    "resultado = train_decision_tree(train, test, \"passenger_survived\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_squared: 0.2122905027932961\n",
      "accuracy o exactitud 0.7877094972067039\n",
      "porcentaje de error 0.2122905027932961\n",
      "precision_score 0.7068965517241379\n",
      "recall_score 0.6612903225806451\n",
      "f1 score 0.6833333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.66129</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  porcentaje_error  precision_score  recall_score  \\\n",
       "decision_tree  0.787709          0.212291         0.706897       0.66129   \n",
       "\n",
       "               f1_score  \n",
       "decision_tree  0.683333  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test.iloc[:, test.columns == \"passenger_survived\"]\n",
    "evaluation_matrix = agegar_resultados(y_test, resultado[0], 'decision_tree')\n",
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(train, test, y):\n",
    "    \n",
    "    X_train = train.iloc[:, train.columns != y]\n",
    "    Y_train = train.iloc[:, train.columns == y].to_numpy().flatten()\n",
    "    x_test = test.iloc[:, test.columns != y]\n",
    "    y_test = test.iloc[:, test.columns == y].to_numpy().flatten()\n",
    "    \n",
    "\n",
    "    #Modelo SVM\n",
    "    clf = svm.SVC(kernel='linear') \n",
    "\n",
    "    #Entrenamiento\n",
    "    clf.fit(X_train, Y_train)\n",
    "    #Prediccion\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    #Fecha y hora del modelo para almacenar\n",
    "    now = datetime.now()\n",
    "    fecha_hora = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    #String de configuración para cada experimento\n",
    "    str_experimento = \"SVM_sklearn_\"+fecha_hora\n",
    "    \n",
    "    #Almacena el modelo \n",
    "    dump(clf, str_experimento+\".joblib\") \n",
    "    \n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    return y_pred, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0], dtype=int64),\n",
       " 0.1787709497206704)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = train_SVM(train, test, \"passenger_survived\")\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_squared: 0.1787709497206704\n",
      "accuracy o exactitud 0.8212290502793296\n",
      "porcentaje de error 0.17877094972067042\n",
      "precision_score 0.7678571428571429\n",
      "recall_score 0.6935483870967742\n",
      "f1 score 0.7288135593220338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  porcentaje_error  precision_score  recall_score  \\\n",
       "decision_tree  0.787709          0.212291         0.706897      0.661290   \n",
       "SVM            0.821229          0.178771         0.767857      0.693548   \n",
       "\n",
       "               f1_score  \n",
       "decision_tree  0.683333  \n",
       "SVM            0.728814  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test.iloc[:, test.columns == \"passenger_survived\"]\n",
    "evaluation_matrix = agegar_resultados(y_test, resultado[0], 'SVM')\n",
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes con numpy y pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.iloc[:, train.columns != \"passenger_survived\"].to_numpy()\n",
    "Y_train = train.iloc[:, train.columns == \"passenger_survived\"].to_numpy()\n",
    "Y_train = Y_train[:, 0]\n",
    "x_test = test.iloc[:, test.columns != \"passenger_survived\"].to_numpy()\n",
    "y_test = test.iloc[:, test.columns == \"passenger_survived\"].to_numpy()\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de prior probability\n",
    "def prior_probability(y):\n",
    "    y_dict = collections.Counter(y)\n",
    "    pre_probab = np.ones(2)\n",
    "    for i in range(0, 2):\n",
    "        pre_probab[i] = y_dict[i]/y.shape[0]\n",
    "    return pre_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de media de las features \n",
    "def mean_var(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    m = np.ones((2, n_features))\n",
    "    v = np.ones((2, n_features))\n",
    "    n_0 = np.bincount(y)[np.nonzero(np.bincount(y))[0]][0] #<<<-----\n",
    "    x0 = np.ones((n_0, n_features))\n",
    "    x1 = np.ones((X.shape[0] - n_0, n_features))\n",
    "    k = 0\n",
    "    for i in range(0, X.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            x0[k] = X[i]\n",
    "            k = k + 1\n",
    "    k = 0\n",
    "    for i in range(0, X.shape[0]):\n",
    "        if y[i] == 1:\n",
    "            x1[k] = X[i]\n",
    "            k = k + 1\n",
    "    for j in range(0, n_features):\n",
    "        m[0][j] = np.mean(x0.T[j])\n",
    "        v[0][j] = np.var(x0.T[j])*(n_0/(n_0 - 1))\n",
    "        m[1][j] = np.mean(x1.T[j])\n",
    "        v[1][j] = np.var(x1.T[j])*((X.shape[0]-n_0)/((X.shape[0]\n",
    "                                                      - n_0) - 1))\n",
    "    return m, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_feature_class(m, v, x):\n",
    "    n_features = m.shape[1]\n",
    "    #print(n_features)\n",
    "    pfc = np.ones(2)\n",
    "    #print(pfc)\n",
    "    for i in range(0, 2):\n",
    "        product = 1\n",
    "        for j in range(0, n_features):\n",
    "            #print(1/np.sqrt(2*3.14*v[i][j]))\n",
    "            #print(1/np.sqrt(2*3.14*v[i][j]))\n",
    "            product = product * (1/np.sqrt(2*math.pi*v[i][j])) * math.exp(-0.5\n",
    "                                 * pow((x[j] - m[i][j]),2)/v[i][j])\n",
    "            #print(x)\n",
    "        pfc[i] = product\n",
    "    return pfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X, y, x):\n",
    "    m, v = mean_var(X, y)\n",
    "    pfc = prob_feature_class(m, v, x)\n",
    "    pre_probab = prior_probability(y)\n",
    "    pcf = np.ones(2)\n",
    "    total_prob = 0\n",
    "    for i in range(0, 2):\n",
    "        total_prob = total_prob + (pfc[i] * pre_probab[i])\n",
    "    for i in range(0, 2):\n",
    "        pcf[i] = (pfc[i] * pre_probab[i])/total_prob\n",
    "    prediction = int(pcf.argmax())\n",
    "    return m, v, pre_probab, pfc, pcf, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " 0.24022346368715083)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_naive_bayes(train, test, y):\n",
    "    \n",
    "    X_train = train.iloc[:, train.columns != y].to_numpy()\n",
    "    Y_train = train.iloc[:, train.columns == y].to_numpy()\n",
    "    Y_train = Y_train[:, 0]\n",
    "    x_test = test.iloc[:, test.columns != y].to_numpy()\n",
    "    y_test = test.iloc[:, test.columns == y].to_numpy()\n",
    "\n",
    "    pred = np.empty(0)\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x = np.array(x_test[i])\n",
    "        #print(x)\n",
    "        m, v, pre_probab, pfc, pcf, prediction = naive_bayes(X_train, Y_train, x)\n",
    "        #print(prediction)\n",
    "        pred = np.append(pred, prediction)\n",
    "\n",
    "    #print(y_test.flatten())\n",
    "    error = mean_squared_error(y_test, pred)\n",
    "    return pred, error\n",
    "\n",
    "resultado = train_naive_bayes(train, test, \"passenger_survived\")\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_squared: 0.24022346368715083\n",
      "accuracy o exactitud 0.7597765363128491\n",
      "porcentaje de error 0.24022346368715086\n",
      "precision_score 0.6301369863013698\n",
      "recall_score 0.7419354838709677\n",
      "f1 score 0.6814814814814814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  porcentaje_error  precision_score  recall_score  \\\n",
       "decision_tree  0.787709          0.212291         0.706897      0.661290   \n",
       "SVM            0.821229          0.178771         0.767857      0.693548   \n",
       "naive_bayes    0.759777          0.240223         0.630137      0.741935   \n",
       "\n",
       "               f1_score  \n",
       "decision_tree  0.683333  \n",
       "SVM            0.728814  \n",
       "naive_bayes    0.681481  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test.iloc[:, test.columns == \"passenger_survived\"]\n",
    "evaluation_matrix = agegar_resultados(y_test, resultado[0], 'naive_bayes')\n",
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg. logística binaria(sigmoid)  en Tensorflow con regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de error o de costo del modelo\n",
    "\n",
    "def error(y_real,y_aprox):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(labels = y_real, logits = y_aprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de entrenamiento de regresion logistica\n",
    "def train_log_reg(x, y, x_test, y_test, n, lr, epochs, n_visualizaciones):\n",
    "\n",
    "    #Reinicio del grafo\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"Hiperparametros\"):\n",
    "        #Hiperparametros\n",
    "        learning_rate = lr\n",
    "        training_epochs = epochs\n",
    "    \n",
    "    with tf.name_scope(\"Parametros_entrenables\"):\n",
    "        #Parametros entrenables del modelo iniciando en 0,0\n",
    "        par_entrenables = tf.Variable(tf.zeros([n, 2]), \n",
    "                                      dtype=tf.float32, name = \"parametros_entrenables\",)\n",
    "        l_rate = tf.get_variable(\"l_rate\",dtype=tf.float32, shape=[], \n",
    "                                 initializer=tf.zeros_initializer())\n",
    "        b = tf.Variable(tf.zeros([2])) \n",
    "\n",
    "    with tf.name_scope(\"Placeholders\"):\n",
    "        #Datos para el modelo, tam_muesta = total de elementos que tiene el modelo \n",
    "        tensor_x = tf.placeholder(tf.float32,[None, n],\"tensor_x\")\n",
    "        tensor_y = tf.placeholder(tf.float32,[None, 2],\"tensor_y\")\n",
    "    \n",
    "    with tf.name_scope(\"Prediccion_y-hat\"):\n",
    "        y_hat = tf.nn.sigmoid(tf.add(tf.matmul(tensor_x, par_entrenables), b), name = \"predicciones-y_hat\")\n",
    "    \n",
    "    with tf.name_scope(\"ErrorMedio\"):\n",
    "        val_error = tf.reduce_mean(error(tensor_y,y_hat), name = \"Calculo_error\")\n",
    "        es_error = tf.summary.scalar(name='es_error', tensor=val_error)\n",
    "    \n",
    "    with tf.name_scope(\"Gradientes\"):\n",
    "        gradiente = tf.gradients(error(tensor_y,y_hat),par_entrenables, name = \"Calculo_gradientes\")\n",
    "    \n",
    "    with tf.name_scope(\"Nuevos-Parametros\"):\n",
    "        actualizacion_parametros = tf.assign(par_entrenables, tf.reshape(\n",
    "            tf.math.subtract(par_entrenables, (l_rate * gradiente)), [n, 2]), \n",
    "                                             name = \"Actualizacion_parametros\")\n",
    "        \n",
    "    #Crea una sesion\n",
    "    with tf.train.MonitoredSession() as session:\n",
    "        #Agrega las observaciones a un vextor con valores: 1, x1, x2...\n",
    "\n",
    "        #Diccionario de entrada con valores de X y Y del modelo\n",
    "        #Envia todo el set de datos al modelo\n",
    "        feed_dict = {tensor_x:x, tensor_y:y, l_rate:learning_rate}\n",
    "        \n",
    "        #Logs con TensorBoard\n",
    "        now = datetime.now()\n",
    "        fecha_hora = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        #String de configuración para cada experimento\n",
    "        path = \"./logs/train_log_reg_\"+fecha_hora + \"_lr=\" + str(lr) + \"_epochs=\" +  str(epochs)\n",
    "        print(\"String experimento:\", path)\n",
    "        \n",
    "        #Imprime grafo en TensorBoard\n",
    "        writer = tf.summary.FileWriter(path, session.graph)\n",
    "        \n",
    "        #Interacion por cada epoch, segun fue definido\n",
    "        for i in range(training_epochs):\n",
    "\n",
    "            #Imprime los valores del error cada cierta cantidad de interaciones\n",
    "            if (i) % n_visualizaciones == 0: \n",
    "                #Derivadas parciales del error \n",
    "                session.run(gradiente,feed_dict=feed_dict)\n",
    "                s = session.run(par_entrenables,feed_dict=feed_dict)\n",
    "                print(\"Ejecucion:\", i, \"\\nerror: \", session.run(val_error,feed_dict=feed_dict))\n",
    "            else:\n",
    "                session.run(gradiente,feed_dict=feed_dict)\n",
    "            \n",
    "            #Error a TensorBoard\n",
    "            summary = session.run(es_error,feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            #Actualiza a los nuevos parametros\n",
    "            session.run(actualizacion_parametros,feed_dict=feed_dict)\n",
    "\n",
    "            #Predicciones segun los nuevos parametros\n",
    "            predicciones = session.run(y_hat,feed_dict=feed_dict)\n",
    "            \n",
    "        #Almacenar parametros de prediccion\n",
    "        parametros_entre = session.run(par_entrenables,feed_dict=feed_dict)\n",
    "        str_experimento = \"log_reg_\"+fecha_hora + \"_lr=\" + str(lr) + \"_epochs=\" +  str(epochs)\n",
    "        np.save(str_experimento, parametros_entre)\n",
    "        \n",
    "        #Prediccion final con test\n",
    "        feed_dict = {tensor_x:x_test, tensor_y:y_test, l_rate:learning_rate}\n",
    "        pred = session.run(y_hat,feed_dict=feed_dict)\n",
    "        writer.close()\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico del grafo\n",
    "\n",
    "![title](img/grafo-train_log_reg_20200629.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] (891, 111)\n",
      "Y_data\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]] (891, 2)\n",
      "x_train: (569, 111) x_test: (179, 111) x_validation: (143, 111)\n",
      "y_train: (569, 2) y_test: (179, 2) y_validation: (143, 2)\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "String experimento: ./logs/train_log_reg_20200629-180809_lr=0.01_epochs=50\n",
      "Ejecucion: 0 \n",
      "error:  0.7240757\n",
      "Ejecucion: 2 \n",
      "error:  0.6718648\n",
      "Ejecucion: 4 \n",
      "error:  0.65704036\n",
      "Ejecucion: 6 \n",
      "error:  0.6479404\n",
      "Ejecucion: 8 \n",
      "error:  0.6413755\n",
      "Ejecucion: 10 \n",
      "error:  0.6362801\n",
      "Ejecucion: 12 \n",
      "error:  0.6322115\n",
      "Ejecucion: 14 \n",
      "error:  0.6289329\n",
      "Ejecucion: 16 \n",
      "error:  0.62626886\n",
      "Ejecucion: 18 \n",
      "error:  0.62407637\n",
      "Ejecucion: 20 \n",
      "error:  0.6222442\n",
      "Ejecucion: 22 \n",
      "error:  0.62068844\n",
      "Ejecucion: 24 \n",
      "error:  0.61934906\n",
      "Ejecucion: 26 \n",
      "error:  0.6181807\n",
      "Ejecucion: 28 \n",
      "error:  0.61715066\n",
      "Ejecucion: 30 \n",
      "error:  0.61623293\n",
      "Ejecucion: 32 \n",
      "error:  0.6154091\n",
      "Ejecucion: 34 \n",
      "error:  0.61466336\n",
      "Ejecucion: 36 \n",
      "error:  0.6139842\n",
      "Ejecucion: 38 \n",
      "error:  0.6133618\n",
      "Ejecucion: 40 \n",
      "error:  0.61278844\n",
      "Ejecucion: 42 \n",
      "error:  0.61225784\n",
      "Ejecucion: 44 \n",
      "error:  0.6117647\n",
      "Ejecucion: 46 \n",
      "error:  0.6113047\n",
      "Ejecucion: 48 \n",
      "error:  0.6108735\n"
     ]
    }
   ],
   "source": [
    "X_data = data.iloc[:, data.columns != \"passenger_survived\"]\n",
    "Y_data = data.iloc[:, data.columns == \"passenger_survived\"]   \n",
    "#One hot\n",
    "oneHot = OneHotEncoder() \n",
    "#print(\"X_train\\n\", X_train, X_train.shape)\n",
    "#print(\"Y_train\\n\", Y_train, Y_train.shape)\n",
    "# Encoding x_orig \n",
    "oneHot.fit(X_data) \n",
    "X_data = oneHot.transform(X_data).toarray() \n",
    "  \n",
    "# Encoding y_orig \n",
    "oneHot.fit(Y_data) \n",
    "Y_data = oneHot.transform(Y_data).toarray() \n",
    "print(\"X_data\\n\", X_data, X_data.shape)\n",
    "print(\"Y_data\\n\", Y_data, Y_data.shape)\n",
    "\n",
    "x_train, x_test = train_test_split(X_data, test_size=0.20, random_state = 10)\n",
    "x_train, x_validation = train_test_split(x_train, test_size=0.20, random_state = 10)\n",
    "print(\"x_train:\", x_train.shape, \"x_test:\", x_test.shape, \"x_validation:\", x_validation.shape)\n",
    "\n",
    "y_train, y_test = train_test_split(Y_data, test_size=0.20, random_state = 10)\n",
    "y_train, y_validation = train_test_split(y_train, test_size=0.20, random_state = 10)\n",
    "print(\"y_train:\", y_train.shape, \"y_test:\", y_test.shape, \"y_validation:\", y_validation.shape)\n",
    "m, n = x_train.shape\n",
    "\n",
    "#print(\"\\n\\n\\nx_train\", x_train, \"\\n\\ny_train\", y_train, \"\\n\\nx_test\", x_test, \"\\n\\ny_test\", y_test, \"\\nn\",n)\n",
    "predic = train_log_reg(x_train, y_train, x_test, y_test, n, 0.01, 50, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/error-train_log_reg_20200629.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "error_squared: 0.17318435754189945\n",
      "accuracy o exactitud 0.8268156424581006\n",
      "porcentaje de error 0.17318435754189943\n",
      "precision_score 0.8297872340425532\n",
      "recall_score 0.6290322580645161\n",
      "f1 score 0.7155963302752293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.173184</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.715596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  porcentaje_error  precision_score  recall_score  \\\n",
       "decision_tree  0.787709          0.212291         0.706897      0.661290   \n",
       "SVM            0.821229          0.178771         0.767857      0.693548   \n",
       "naive_bayes    0.759777          0.240223         0.630137      0.741935   \n",
       "reg_logistica  0.826816          0.173184         0.829787      0.629032   \n",
       "\n",
       "               f1_score  \n",
       "decision_tree  0.683333  \n",
       "SVM            0.728814  \n",
       "naive_bayes    0.681481  \n",
       "reg_logistica  0.715596  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(y_test)\n",
    "predic[0:predic.shape[0],]\n",
    "resultado = []\n",
    "for i in range(predic.shape[0]):\n",
    "    if predic[i, 0] > predic[i, 1]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(1)\n",
    "\n",
    "print(resultado)\n",
    "Y_data = data.iloc[:, data.columns == \"passenger_survived\"]  \n",
    "y_train, y_test = train_test_split(Y_data, test_size=0.20, random_state = 10)\n",
    "y_train, y_validation = train_test_split(y_train, test_size=0.20, random_state = 10)\n",
    "\n",
    "\n",
    "evaluation_matrix = agegar_resultados(y_test, resultado, 'reg_logistica')\n",
    "evaluation_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds Cross Validation\n",
    "\n",
    "K-Fold Cross Validation busca resolver el treade-off entre el utilizar el dataset completo para un entrenameinto mas efectico (con mayor cantidad de datos), y tener una buena muestra del dataset para su posterior evaluación. \n",
    "\n",
    "La idea es utilizar todo el dataset para el entrenamiento y todo el dataset para la validación, teniendo en cuenta que cuando realizamos validación siempre debe de ser con datos con los que no fue entrenado el modelo. \n",
    "\n",
    "\n",
    "![title](img/ejemplo_cross_validation.png)\n",
    "\n",
    "La imagen anterior nos muestra como funcionaria Cross Validation utilizando un k = 5, el algoritmo seria el siguiente:\n",
    "\n",
    "1. Tomamos todo el dataset y este se divide en 5 partes de tamaño x.\n",
    "2. Guardamos la primer parte de la division para el proceso de validación, y ejecutamos el proceso de entrenamiento con las otras 4 partes restantes.\n",
    "3. Una vez entrenado el modelo, utilizamos la primer parte del dataset para validarlo, y obtenemos un resultado. \n",
    "4. Repetir el proceso anterior tomando cada vez una parte diferente para el proceso de validación, y las otras 4 restantes para el entrenamiento. \n",
    "5. Para definir una metrica de evaluación entre todos los procesos de entrenamiento, promediamos el valor de cada validación realizada.\n",
    "\n",
    "K-Folds Cross Validation, definitivamente ubiera sido de gran utilidad para esta preactica, ya que tenemos una mejor idea de como se comportarían nuestros modelo, utilizando todos los datos del dataset para el aprendizaje y la evaluación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Matriz de evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>porcentaje_error</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.681481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.173184</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.715596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  porcentaje_error  precision_score  recall_score  \\\n",
       "decision_tree  0.787709          0.212291         0.706897      0.661290   \n",
       "SVM            0.821229          0.178771         0.767857      0.693548   \n",
       "naive_bayes    0.759777          0.240223         0.630137      0.741935   \n",
       "reg_logistica  0.826816          0.173184         0.829787      0.629032   \n",
       "\n",
       "               f1_score  \n",
       "decision_tree  0.683333  \n",
       "SVM            0.728814  \n",
       "naive_bayes    0.681481  \n",
       "reg_logistica  0.715596  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones \n",
    "\n",
    "* A partir de la metriz de evaluacion de los modelos generados, se puede estimar mediate la metrica de f1 score, que los modelos de regresión logistica ejecutado en Tensorflow y el modelo Support Vector Machines SVM, de sklearn, fueron los que mejor resultado tuvieron, si se debe de elegir solamente uno, creo que el de SVM sería el mas adecuado para la prediccion de datos de este modelo.\n",
    "* La matriz de evaluación es muy util para estimar la evaluación de los modelos, a partir de ella se pueden priorizar modelos, según sea la prioridad de estudiar. Si solo me interesaría la evaluacion de las predicciones correctas, con la regresión logistica de tensorflow seria suficiente, ya que cuenta con un 82.6% de accuracy. Si lo que necesitamos es reducir los falsos negarivos, el recall score de naive bayes es el adecuado. \n",
    "\n",
    "\n",
    "# Recomendaciones\n",
    "\n",
    "* A partir de la investifacion de Cross Validation y la evaluación de los modelos ejecutados, creo que seria muy conveniente aplicar K-Folds Cross Validation para tener una metrica mas clara de las metricas de los modelos, sobre todo en modelos pequeños como el actual, conde una ejecucción de k aprendizajes no representaria tanto tiempo de aprendizaje. \n",
    "* Es recomendado determinar uns prioridad especifica para las metricas de evaluación del modelo, con la finalidad de centrar el resultado de los modelos en esta metrica y proveer un camino de optimización para el aprendizaje del modelo. \n",
    "\n",
    "\n",
    "# Experiencia, dificultades y lecciones aprendidas\n",
    "\n",
    "* Creo que la major experiencia es la del almecenamiento del modelo entrenado para poder producir predicciones en otro notebook, creo que fue lo mas importante para el futuro, ya que en la realidad creo que es así como normalmente se deberia de trabajar, en un sistema especifico de entrenamiento y otro diferente de aprendizaje. \n",
    "* La mayor dificultad fue la de realizar naive bayes de forma vectorizada y efectiva, se me dificulto demasiado entender como realizarlo, a pesar de que el algoritmo en sí es muy fácil.\n",
    "* Realmente son muchas las lecciones aprendidas, sobre todo como comentaba anteriormente, el alamcenamiento del modelo para ejecutarlo en otro entorno, el algoritmo de F-Folds, y las distintas metricas de evaluación, que se aplican según la importancia de lo que se desea evaluar, o hacia donde se debe de ajustar el modelo predictivo. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
